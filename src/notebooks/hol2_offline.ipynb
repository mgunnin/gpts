{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary dependencies to run the notebook\n",
    "# python -m pip install -U pip pandas setuptools wheel pandas_profiling autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from local file\n",
    "df = pd.read_json('/Users/mattgunnin/Sites/AI/20_GPT/gpt_lolcoach/data/lol/export.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cff20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML report for Exploratory Data Analysis\n",
    "report = ProfileReport(df, title=\"Matchups Exploration\", html={'style': {'full_width': True}})\n",
    "\n",
    "report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f93fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 5 first rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display list of columns in the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4071be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some stats from pandas (also findable in the AutoGluon HTML report)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dadbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AutoGluon Tabular Dataset \n",
    "# https://auto.gluon.ai/stable/tutorials/tabular_prediction/index.html\n",
    "df = TabularDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d431589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't want (identifiers)\n",
    "def _drop_column(df, col_name=list()):\n",
    "    for x in col_name:\n",
    "        try:\n",
    "            df.drop([x],\n",
    "                axis=1,\n",
    "                inplace=True)\n",
    "        except KeyError:\n",
    "            print('{} already dropped from df'.format(x))\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = _drop_column(df, col_name=['puuid', 'summonerName'])\n",
    "\n",
    "# Perform 80-20% train-test split\n",
    "train = df.sample(frac=0.8, random_state=200) # random state is a seed value\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New look at the data - one example\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0c861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine the label in our TabularDataset we want to predict\n",
    "label = 'win'\n",
    "\n",
    "\n",
    "# Create the tabular predictor with the target label by passing the training test\n",
    "predictor = TabularPredictor(label=label,\n",
    "                path='./autogluon_trained_models_liveclient_classifier').fit(train, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940563c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a test prediction from original test dataset\n",
    "y_test = test[label] # we want 'win' column to be predicted\n",
    "\n",
    "\n",
    "test_data_nolabel = test.drop(columns=[label])  # delete label column, also drop identifier column\n",
    "# We have the testing dataset ready\n",
    "test_data_nolabel.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the model \n",
    "predictor = TabularPredictor.load('./autogluon_trained_models_liveclient_classifier')\n",
    "\n",
    "# Predict test values\n",
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "\n",
    "# Evaluate prediction performance\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f93f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing models\n",
    "predictor.leaderboard(test, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the best model, display feature importance\n",
    "predictor.feature_importance(test,\n",
    "                            subsample_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions from incoming data\n",
    "# goldearned, totalminionskilled, win, kills, assists, deaths, champion, visionscore, totaldamagedealttochampions, gameversion\n",
    "# [5506, 134, false, 0, 1, 3, Jayce, 7, 2350, 11.15.389.2308]\n",
    "data = [5506, 134, 0, 1, 3, 'Jayce', 7, 2350, '11.15.389.2308']\n",
    "\n",
    "# From a list, load it into a dataframe and specify column names for consistency\n",
    "test_d = pd.DataFrame([data], columns=['goldearned', 'totalminionskilled', 'kills', 'assists', 'deaths',\n",
    "                                       'champion', 'visionscore', 'totaldamagedealttochampions', 'gameversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9423ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [91, 35, 0, 1080321, 2204, 390, 225, 0, 10, 0, 672, 0, 220, 0, 94, 0, 1047, 33]\n",
    "#test_d = pd.DataFrame([data], columns=['magicResist', 'healthRegenRate', 'spellVamp', 'timestamp', 'maxHealth', 'moveSpeed', 'attackDamage', 'armorPenetrationPercent', 'lifesteal', 'abilityPower', 'resourceValue', 'magicPenetrationFlat', 'attackSpeed', 'currentHealth', 'armor', 'magicPenetrationPercent', 'resourceMax', 'resourceRegenRate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictor.predict(test_d)\n",
    "\n",
    "# Print how probable each class is\n",
    "print(predictor.predict_proba(test_d).iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
